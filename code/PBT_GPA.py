import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import random_split
from enum import Enum, auto
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
from pathlib import Path

import ray
from ray import tune
from ray.util.placement_group import (
    placement_group,
    placement_group_table,
    remove_placement_group,
)
from ray.util.scheduling_strategies import PlacementGroupSchedulingStrategy

from numpy import random
import time
import copy
import os
import heapq
import json
import math
import matplotlib.pyplot as plt
import argparse
import threading

# Trial scheduling chioce
class TrialMode(Enum):
    ERA = "ERA"
    ETA = "ETA"

DATA_PATH = "~/Documents/workspace/tune_population_based/"

DIR_PATH = "~/Documents/workspace/TBS_for_1/"


HEAD_NODE_IP = "PLEASE EXCHANGE YOUR HEAD NODE IP!"     # é ­ç¯€é»IP
HYPER_NUM = 50                      # è¶…åƒæ•¸æ•¸é‡
BATCH_SIZE = [32, 64, 128, 256, 512]     # è¨“ç·´ä¸€å€‹interationçš„batch size
STOP_ITER = 1000                    # å…±è¨“ç·´å¹¾å€‹iteration
STOP_ACC = 0.8                      # è¨“ç·´åˆ°æº–ç¢ºç‡åœæ­¢
INTERVAL_REPORT = 30                # é–“éš”å¤šä¹…åœ¨ternimalä¸­é¡¯ç¤ºåŸ·è¡Œéç¨‹
INTERVAL_CHECK = 50
STAGE = 100
SLOPE = 0.9
STALENESS = True                  # æ˜¯å¦è€ƒæ…®Staleness

MAX_RETIRE_NODES = 9  # æœ€å¤§å¯æ·˜æ±°ç¯€é»æ•¸é‡
LATE_STAGE = 0.8  # é€²å…¥å¾ŒæœŸçš„é–€æª»
RESOURCE_ALLOCATION = {}

with Path("./score.json").open("r") as f:
    RESOURCE_ALLOCATION = json.load(f)
# TEST_SIZE = 25


# å»ºç«‹data_loader
def get_data_loader(model_type, batch_size = 64, data_dir="~/Documents/workspace/tune_population_based/data"):
    # å¼·åˆ¶è½‰æˆ Python intï¼Œé¿å… numpy.int64 è§¸ç™¼ DataLoader æª¢æŸ¥éŒ¯èª¤
    batch_size = int(batch_size)

    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    if model_type == "resnet-18":
        train_loader = torch.utils.data.DataLoader(
            torchvision.datasets.CIFAR10(
                root=data_dir, train=True, download=True, transform=transform
            ),
            batch_size=batch_size,
            shuffle=True,
        )
        test_loader = torch.utils.data.DataLoader(
            torchvision.datasets.CIFAR10(
                root=data_dir, train=False, download=True, transform=transform
            ),
            batch_size=batch_size,
            shuffle=False,
        )
    elif model_type == "resnet-50":
        train_loader = torch.utils.data.DataLoader(
            torchvision.datasets.CIFAR100(
                root=data_dir, train=True, download=True, transform=transform
            ),
            batch_size=batch_size,
            shuffle=True
        )

        test_loader = torch.utils.data.DataLoader(
            torchvision.datasets.CIFAR100(
                root=data_dir, train=False, download=True, transform=transform
            ),
            batch_size=batch_size,
            shuffle=False
        )
    return train_loader, test_loader
# æ¨¡å‹è¨“ç·´
def train(model, optimizer, train_loader, device=None):
    model.train()
    criterion = nn.CrossEntropyLoss().to(device)
    for (inputs, targets) in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        break


def test(model, test_loader, device):
    total = 0
    correct = 0
    with torch.no_grad():
        for inputs, targets in test_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    return correct / total



# ç”¨ä¾†é¡¯ç¤ºç•¶å‰æ‰€æœ‰Trailçš„ç‹€æ…‹ (åœ¨commandä¸­é¡¯ç¤º)
@ray.remote(num_cpus = 0.1, resources={"node:"+HEAD_NODE_IP: 0.1})
def Reporter(tuner, max_report_frequency = 5, hyper_num = 1):
    start_time = ray.get(tuner.get_start_time.remote())
    resource = ray.get(tuner.get_resource.remote())
    while True:
        hypers, accuracy, state, perturbs, running_trial_num, package_size = ray.get(tuner.get_for_reporter.remote())
        m, s = divmod(time.time() - start_time, 60)
        h, m = divmod(m, 60)
        if "CPU" in ray.available_resources():
            unused_cpu_num = ray.available_resources()["CPU"]
        else:
            unused_cpu_num = 0
        if "GPU" in ray.available_resources():
            unused_gpu_num = ray.available_resources()["GPU"]
        else:
            unused_gpu_num = 0

        print("== Status ==")
        print(f'Current Time : {time.ctime() } (runnung for {str(int(h)).zfill(2)}:{str(int(m)).zfill(2)}:{str(int(s)).zfill(2)})')
        print(f"Unused Resource : {unused_cpu_num} CPUs and {unused_gpu_num} GPUs")
        print(f"PBT : {perturbs} perturbs")
        print(f'Total hypers : {hyper_num} ( {running_trial_num} is training ), package_size : {package_size}')
        print("+--------------+------------+------------+---------------------+------------+------------+------------+----------+-------+-----------------+")
        print("| Hyper name   |   Status   |  CPU / GPU |                  IP |         lr |   momentum | batch_size |      acc |  iter |   total time (s)|")
        print("+--------------+------------+------------+---------------------+------------+------------+------------+----------+-------+-----------------+")
        for i, (hyper, acc, sta) in enumerate(zip(hypers, accuracy, state)):
            if sta["resource_id"] == -2:
                status = "TERNIMAL"
                cpus_per_trial = 0
                gpus_per_trial = 0
                ip = "node:0.0.0.0"
            elif sta["resource_id"] == -1:
                status = "PENDING"
                cpus_per_trial = 0
                gpus_per_trial = 0
                ip = "node:0.0.0.0"
            else:
                status = "RUNNING"
                cpus_per_trial = resource[sta["resource_id"]]["CPU"]
                gpus_per_trial = resource[sta["resource_id"]]["GPU"]
                ip = resource[sta["resource_id"]]["node"]

            print(f'| hyper_{str(i).zfill(5)}  |   {status:^8}   | {cpus_per_trial:>4.1f} / {gpus_per_trial:<3.1f} | {ip:>19} | {hyper["lr"]:10.6f} | {hyper["momentum"]:10.6f} | {hyper["batch_size"]:>11}| {acc:8.4f} | {sta["iteration"]:>5} | {sta["run_time"]:15.6f} | ')
        print("+--------------+------------+------------+---------------------+------------+------------+------------+----------+-------+-----------------+")
        time.sleep(max_report_frequency)

@ray.remote(num_cpus = 0.2, resources={"node:"+HEAD_NODE_IP: 0.1})
class Tuner(object):
    """
        Tuner : æ§åˆ¶æ‰€æœ‰Trialé€²ç¨‹, å‰µå»ºèˆ‡æ¥æ”¶Trialçš„çµæœã€‚

        Args:
            hyper_num : å…±å»ºç«‹å¤šå°‘hyperçµ„åˆ
            batch_siz : ä¸€å€‹iterationè¨“ç·´çš„batchå¤§å°
            stop_acc : è¨“ç·´åœæ­¢çš„accuracyæ¢ä»¶
            stop_iteration : è¨“ç·´åœæ­¢çš„iterationæ¢ä»¶
            checkpoint_interval : å¤šå°‘iterationå­˜ä¸€å€‹checkpoint
            trials_state : å­˜æ¯ç­†hyperè¨“ç·´ä½¿ç”¨çš„è³‡æºidï¼Œä»¥åŠè¨“ç·´èŠ±è²»æ™‚é–“
            resource : å­˜é€™æ¨£åˆ†é…(RESOURCE_ALLOCATION)ç¸½å…±æœ‰å¤šå°‘çµ„è³‡æº
            avaliable_resource : å­˜ç›®å‰å¯ç”¨è³‡æº (æ­£åœ¨ä½¿ç”¨å’Œæ•ˆèƒ½å¤ªå·®å°±ä¸æœƒåœ¨è£¡é¢)
            trials_scheduler : å­˜è¦è¨“ç·´çš„hyper_id (åˆ°é”çµ‚æ­¢æ¢ä»¶çš„å°±ä¸æœƒåœ¨è£¡é¢)
            running_trial_num : æ­£åœ¨åŸ·è¡Œè¨“ç·´çš„trialæ•¸é‡
            min_run_one_interval_time : åŸ·è¡Œä¸€å€‹intervalæœ€å°‘éœ€è¦çš„æ™‚é–“ (ç•¶è¨ˆç®—æ¯å€‹è³‡æºèƒ½åŠ›çš„åŸºç¤)

    """
    def __init__(
        self,
        hyper_num = 1,
        model_type = "resnet-18",
        resource_allocation = None,
        trial_allocation = None,
        stop_acc = 1,
        stop_iteration = 0,
        checkpoint_interval = 5,
        hyperparam_mutations = None,
        path = None,
        trialmode = "ERA",
        log_dir = None,  # æ–°å¢ï¼šæ¨¡å¼å°ˆå±¬è¼¸å‡ºè³‡æ–™å¤¾
        comm_log_filename=None, # æ–°å¢: é€šè¨Šæ™‚é–“è¨˜éŒ„æª”æ¡ˆ
        max_retire_nodes=0, # <-- [æ–°å¢] æ¥æ”¶æ·˜æ±°æ•¸é‡
    ):
        self.start_time = time.time()
        self.tuner = None
        self.hyper_num = hyper_num
        self.model_type = model_type
        self.stop_acc = stop_acc
        self.stop_iteration = stop_iteration
        self.checkpoint_interval = checkpoint_interval
        self.hyperparam_mutations = hyperparam_mutations
        self.path = path
        self.log_dir = log_dir  # æ–°å¢ï¼šä¿å­˜è·¯å¾‘
        self.comm_log_filename = comm_log_filename # æ–°å¢: é€šè¨Šæ™‚é–“è¨˜éŒ„æª”æ¡ˆ

        self.MAX_RETIRE_NODE_COUNT = max_retire_nodes # <-- [æ–°å¢] å„²å­˜æ·˜æ±°æ•¸é‡

        if isinstance(trialmode, TrialMode):
            self.trialmode = trialmode
        else:
            self.trialmode = TrialMode(trialmode.upper())
        self._schedule_fn = self.choice_create_trial(self.trialmode)

        self.trials_scheduler = []
        self.hypers = []
        self.trials_state = []
        self.checkpoints = []
        self.last_checkpoint = [0] * hyper_num
        self.perturbs = 0
        self.trial_acc_list = [0] * hyper_num
        self.resource = []
        self.avaliable_resource = []

        self.running_trial_num = 0
        self.running_resource_num = 0
        self.min_run_one_interval_time = 9999
        self.max_iter = 0
        self.max_acc = -1
        self.last_run_interval = 9999
        self.package_size = 0

        self.start_trial_time = []
        self.resource_run_time = []

        # æ–°å¢ï¼šç´€éŒ„å„ç¯€é»æ­·å²ä¸Šä½¿ç”¨éçš„ batch sizeï¼ˆé›†åˆï¼‰
        self.node_batch_sizes_history = {}
        self.trial_allocation = trial_allocation
        self.communication_total_cost = 0.0

        # --- [æ–°å¢] æ·˜æ±°ç¯€é»ç›¸é—œ ---
        self.LATE_STAGE_ITER_THRESHOLD = 0 # å°‡åœ¨ set_placement_group ä¸­è¨­å®š
        self.weak_nodes_retired_set = set() # å„²å­˜å·²æ·˜æ±°çš„ node_id
        self.weakest_node_ids = set() # å„²å­˜ã€Œå€™é¸æ·˜æ±°ã€çš„ node_id
        # --- [æ–°å¢çµæŸ] ---

        self.initialize_all_config()
        self.set_placement_group(resource_allocation)

    # --- [æ–°å¢å‡½å¼] ---
    def _retire_idle_weak_nodes(self):
        """
        æª¢æŸ¥æ˜¯å¦é€²å…¥ã€Œå¾ŒæœŸã€ï¼Œå¦‚æœæ˜¯ï¼Œå‰‡å¾ avaliable_resource ä¸­
        ç§»é™¤æ‰€æœ‰é–’ç½®çš„ã€Œè¼ƒå¼±ç¯€é»ã€ï¼Œç›´åˆ°é”åˆ° N çš„ä¸Šé™ã€‚
        """
        # 1. æª¢æŸ¥æ˜¯å¦é€²å…¥ã€Œå¾ŒæœŸã€æˆ–æ˜¯å¦è¨­å®šäº†æ·˜æ±°
        #    (å¦‚æœ MAX_RETIRE_NODE_COUNT æ˜¯ 0ï¼Œæˆ– weakest_node_ids æ˜¯ç©ºçš„ï¼Œå°±ç›´æ¥è¿”å›)
        if self.max_iter < self.LATE_STAGE_ITER_THRESHOLD or not self.weakest_node_ids:
            return

        # 2. æª¢æŸ¥æ˜¯å¦å·²é”æ·˜æ±°ä¸Šé™
        if len(self.weak_nodes_retired_set) >= self.MAX_RETIRE_NODE_COUNT:
            return # å·²é”ä¸Šé™ï¼Œä¸å†æ·˜æ±°

        # 3. å¦‚æœé€²å…¥å¾ŒæœŸï¼Œæƒæå¯ç”¨çš„è³‡æºåˆ—è¡¨
        new_available_resource_list = []
        retired_count_this_round = 0

        for resource_id in self.avaliable_resource:
            # å†æ¬¡æª¢æŸ¥æ˜¯å¦å·²é”ä¸Šé™ (å¯èƒ½åœ¨è¿´åœˆä¸­é”åˆ°)
            if len(self.weak_nodes_retired_set) >= self.MAX_RETIRE_NODE_COUNT:
                new_available_resource_list.append(resource_id)
                continue # å·²é”ä¸Šé™ï¼Œåœæ­¢æª¢æŸ¥ï¼Œä¿ç•™å‰©é¤˜ç¯€é»

            # æª¢æŸ¥ç¯€é»æ˜¯å¦ç‚ºã€Œå€™é¸å¼±ç¯€é»ã€
            is_candidate = (resource_id in self.weakest_node_ids)

            # æª¢æŸ¥ç¯€é»æ˜¯å¦ã€Œå·²ç¶“è¢«æ·˜æ±°ã€
            is_already_retired = (resource_id in self.weak_nodes_retired_set)

            if is_candidate and not is_already_retired:
                # é€™æ˜¯å€™é¸å¼±ç¯€é»ï¼Œä¸”å°šæœªé”æ·˜æ±°ä¸Šé™ -> æ·˜æ±°å®ƒ
                print(f"--- é€²å…¥å¾ŒæœŸï¼šæ·˜æ±°é–’ç½®çš„å¼±ç¯€é» {resource_id} (ç¸½æ·˜æ±°: {len(self.weak_nodes_retired_set)+1}/{self.MAX_RETIRE_NODE_COUNT}) ---")
                self.weak_nodes_retired_set.add(resource_id)
                retired_count_this_round += 1
            else:
                # é€™ä¸æ˜¯å¼±ç¯€é»ï¼Œæˆ–å·²é”ä¸Šé™ï¼Œä¿ç•™å®ƒ
                new_available_resource_list.append(resource_id)

        # 4. æ›´æ–°å¯ç”¨çš„è³‡æºåˆ—è¡¨
        if retired_count_this_round > 0:
            self.avaliable_resource = new_available_resource_list
    # --- [æ–°å¢çµæŸ] ---

    # ==========================================
    # æ–°å¢ï¼šå°‡ Trial æ’å…¥åˆ°å·²æ’åºçš„ scheduler ä¸­
    # ==========================================
    def insert_trial(self, tid: int) -> None:
        # æ³¨æ„ï¼šåŸç¨‹å¼ç¢¼è®Šæ•¸ç‚º trials_state (list of dict) å’Œ trials_scheduler (list of int)
        new_iteration = self.trials_state[tid]["iteration"]

        left, right = 0, len(self.trials_scheduler)
        while left < right:
            mid = (left + right) // 2
            # å–å¾—ä¸­é–“é‚£å€‹ trial ID çš„ iteration é€²è¡Œæ¯”è¼ƒ
            mid_tid = self.trials_scheduler[mid]
            if self.trials_state[mid_tid]["iteration"] <= new_iteration:
                left = mid + 1
            else:
                right = mid
        self.trials_scheduler.insert(left, tid)

    # æ–°å¢: create_new_trial ä»¥ç›®å‰é¸å®šçš„ç­–ç•¥æ’ç¨‹
    def create_new_trial(self):
        # --- [æ–°å¢ç¨‹å¼ç¢¼] ---
        # æ¯æ¬¡è¦åˆ†é…æ–°ä»»å‹™å‰ï¼Œéƒ½å…ˆæª¢æŸ¥ä¸¦æ·˜æ±°é–’ç½®çš„å¼±ç¯€é»
        self._retire_idle_weak_nodes()
        # --- [æ–°å¢çµæŸ] ---

        # è‹¥æ²’æœ‰å¯ç”¨è³‡æºæˆ–æ²’æœ‰æ’ç¨‹ä¸­çš„ trialï¼Œå°±ä¸å‹•ä½œ
        if not self.avaliable_resource or not self.trials_scheduler:
            return
        # å‘¼å«å°æ‡‰ç­–ç•¥ï¼ˆERA/ETAï¼‰
        self._schedule_fn()


    # åˆå§‹åŒ–æ¯çµ„hyperçš„å€¼èˆ‡checkpoint
    def initialize_all_config(self):
        if self.model_type == "resnet-18":
            model = models.resnet18()
            model.fc = nn.Linear(model.fc.in_features, 10)
        elif self.model_type == "resnet-50":
            model = models.resnet50()
            model.fc = nn.Linear(model.fc.in_features, 100)
        optimizer = optim.SGD(
            model.parameters(),
            lr=0.1,
            momentum=0.9,
        )

        bs_list = BATCH_SIZE

        for i in range(self.hyper_num):
            hyper = {
                "lr": random.uniform(0.001, 1),
                "momentum": random.uniform(0.001, 1),
                # å°‡ numpy.random.choice çš„å›å‚³è½‰æˆ Python int
                "batch_size": bs_list[i % len(bs_list)],
                "model_type" : self.model_type,
            }
            trial_state = {
                "resource_id" : -1,
                "run_time": 0,
                "iteration" : 0,
            }
            checkpoint = {
                "model_state_dict" : model.state_dict(),
                "optimizer_state_dict" : optimizer.state_dict(),
                "checkpoint_interval" : self.checkpoint_interval,
            }
            self.trials_scheduler.append(i)
            self.hypers.append(hyper)
            self.trials_state.append(trial_state)
            self.checkpoints.append(checkpoint)

    def training_function(config):
        start_time = time.time()
        # æ¨¡æ“¬èˆ‡serveræºé€šçš„æ™‚é–“
        time.sleep(1)
        end_time = time.time()
        communication_time = end_time - start_time
        tune.report(communication_time=communication_time)

    # åˆ†é…æ¯å€‹ç¯€é»åœ¨è¨“ç·´æ™‚èƒ½ä½¿ç”¨çš„è³‡æºæ•¸
    def set_placement_group(self, resource_allocation):
        for nodes in ray.nodes():
            if "CPU" in nodes['Resources'] and nodes['NodeManagerAddress'] in resource_allocation["CPU"]:
                if nodes['NodeManagerAddress'] == HEAD_NODE_IP:
                    sub = 1
                else:
                    sub = 0
                sum_cores = nodes['Resources']['CPU']
                # Check if the node exists in the allocation map
                if nodes['NodeManagerAddress'] in resource_allocation["CPU"]:
                    core_alloc = resource_allocation["CPU"][nodes['NodeManagerAddress']].get('core', 1)
                    score_alloc = resource_allocation["CPU"][nodes['NodeManagerAddress']].get('score', 0)
                    while(int(sum_cores / core_alloc)):
                        self.resource.append({
                            "CPU": core_alloc - sub,
                            "GPU": 0,
                            "node":"node:"+nodes['NodeManagerAddress'],
                            "calculate_ability" : score_alloc,
                            "Used_count" : 0.0,
                        })
                        print(self.resource[-1])
                        sub = 0
                        sum_cores -= core_alloc
            if "GPU" in nodes['Resources'] and nodes['NodeManagerAddress'] in resource_allocation["GPU"]:
                sum_gpus = nodes['Resources']['GPU']
                if nodes['NodeManagerAddress'] in resource_allocation["GPU"]:
                    core_alloc = resource_allocation["GPU"][nodes['NodeManagerAddress']].get('core', 1)
                    score_alloc = resource_allocation["GPU"][nodes['NodeManagerAddress']].get('score', 0)
                    while(int(sum_gpus / core_alloc)):
                        self.resource.append({
                            "CPU": 0,
                            "GPU": core_alloc,
                            "node":"node:"+nodes['NodeManagerAddress'],
                            "calculate_ability" : score_alloc,
                            "Used_count" : 0.0,
                        })
                        print(self.resource[-1])
                        sum_gpus -= core_alloc

        for i in range(len(self.resource)):
            self.avaliable_resource.append(i)

        self.start_trial_time = [0] * len(self.resource)
        # æ–°å¢: é¿å…å¾ŒçºŒä½¿ç”¨æœªåˆå§‹åŒ– self.resource_run_time
        # é è¨­çµ¦ä¸€å€‹è¼ƒå¤§çš„å€¼ï¼ŒETA å°å‡ºæˆ–è©¦ç®—ä¸æœƒå‡ºéŒ¯
        self.resource_run_time = [float('inf')] * len(self.resource)

        # --- [ä¿®æ”¹æ­¤è™•é‚è¼¯] ---
        # 1. å®šç¾©ã€Œå¾ŒæœŸã€çš„é–€æª»ï¼Œä¾‹å¦‚ç¸½ iteration çš„ 80%
        self.LATE_STAGE_ITER_THRESHOLD = self.stop_iteration * LATE_STAGE

        # 2. å»ºç«‹ä¸€å€‹é›†åˆ (set) ä¾†è¿½è¹¤å·²è¢«æ·˜æ±°çš„ç¯€é» (å·²ç§»è‡³ __init__)
        # self.weak_nodes_retired_set = set()

        # 3. æ‰¾å‡º N å€‹æœ€å¼±çš„ç¯€é» ID
        self.weakest_node_ids = set() # å„²å­˜ã€Œå€™é¸æ·˜æ±°ã€çš„ç¯€é» ID

        # æª¢æŸ¥ N > 0 ä¸” è³‡æºæ•¸ > N (å¦‚æœç¸½ç¯€é»æ•¸ <= Nï¼Œæ·˜æ±°å°±æ²’æ„ç¾©äº†)
        if self.MAX_RETIRE_NODE_COUNT > 0 and len(self.resource) > self.MAX_RETIRE_NODE_COUNT:
            # ç²å– (ability, resource_id) çš„åˆ—è¡¨
            # æˆ‘å€‘åªè€ƒæ…® ability > 0 çš„ç¯€é»
            node_abilities = []
            for i, r in enumerate(self.resource):
                ability = r.get("calculate_ability", 0)
                if ability > 0:
                    node_abilities.append((ability, i)) # å„²å­˜ (åˆ†æ•¸, ç´¢å¼•)

            # æŒ‰ç…§ ability æ’åº (ç”±ä½åˆ°é«˜)
            node_abilities.sort(key=lambda x: x[0])

            # å–å¾— N å€‹æœ€å¼±çš„ resource_id
            num_to_select = min(self.MAX_RETIRE_NODE_COUNT, len(node_abilities))
            weakest_nodes_list = [res_id for ability, res_id in node_abilities[:num_to_select]]
            self.weakest_node_ids = set(weakest_nodes_list)

            print(f"âœ… å°‡åœ¨å¾ŒæœŸæ·˜æ±° {len(self.weakest_node_ids)} å€‹æœ€å¼±ç¯€é» (è¨­å®šä¸Šé™: {self.MAX_RETIRE_NODE_COUNT})ã€‚")
            print(f"âœ… å€™é¸æ·˜æ±°ç¯€é» (Weakest Node IDs): {self.weakest_node_ids}")
        else:
            print(f"â„¹ï¸ MAX_RETIRE_NODE_COUNT è¨­ç‚º {self.MAX_RETIRE_NODE_COUNT}ï¼Œä¸åŸ·è¡Œç¯€é»æ·˜æ±°ã€‚")
        # --- [ä¿®æ”¹çµæŸ] ---

    #################
    # æ’ç¨‹ç­–ç•¥é¸æ“‡ğŸ›’ #
    #################

    def choice_create_trial(self, mode):
        if mode == TrialMode.ETA:
            print("âš™ï¸   ETA")
            return self.ETA
        elif mode == TrialMode.ERA:
            print("âš™ï¸   ERA")
            return self.ERA



    #######################
    # æŒ‡æ•¸å¼æ¸›å°‘ç­–ç•¥æ’ç¨‹ğŸ”¢ #
    #######################
    def ERA(self):
        # self.trials_scheduler = sorted(self.trials_scheduler, reverse=False)
        # self.trials_scheduler.sort(key = lambda t: self.trials_state[t]["iteration"])
        remaining_generations = 0
        for trial_state in self.trials_state:
            if trial_state["resource_id"] < 0:
                remaining_generations += math.ceil((self.max_iter - trial_state["iteration"]) / self.checkpoint_interval)
        cc = 1.0

        if not self.trials_scheduler:
            return

        # éæ­·æ‰€æœ‰å¯ç”¨è³‡æºç›´åˆ°è€—ç›¡
        while self.avaliable_resource and self.trials_scheduler:
            resource_id = self.avaliable_resource.pop(0)
            n0 = self.resource[resource_id]["calculate_ability"]
            ids, hypers, checkpoints = [], [], []
            n = 0 # Initialize n

            print('-----åŸæœ¬trialæ•¸---------')
            print(len(self.trials_scheduler))

            # æŒ‡æ•¸è¡°æ¸›åƒæ•¸
            slope = SLOPE
            intervals = STAGE

            x = max(0, (self.stop_iteration - self.last_run_interval) // intervals)

            if n0 >= 1:
                n = math.ceil(n0 * (slope ** x))
                n = min(n, len(self.trials_scheduler))
                print('åŸå§‹Tæ•¸'); print(n0)
                print('ç¸®çŸ­Tæ•¸'); print(n)

                if n <= 0:
                    self.avaliable_resource.append(resource_id)
                    continue

                for i in range(n):
                    tid = self.trials_scheduler.pop(0)
                    ids.append(tid)
                    if (self.stop_iteration - self.trials_state[tid]["iteration"]) < self.checkpoint_interval:
                        self.checkpoints[tid]["checkpoint_interval"] = self.stop_iteration - self.trials_state[tid]["iteration"]
                    else:
                        self.checkpoints[tid]["checkpoint_interval"] = self.checkpoint_interval
                    hypers.append(self.hypers[tid])
                    checkpoints.append(self.checkpoints[tid])
            else: # n0 is 0 or less
                self.avaliable_resource.append(resource_id)
                continue

            # This block should not be reachable if n is 0
            if n == 0:
                # If for some reason n is 0, put resource back and stop
                self.avaliable_resource.append(resource_id)
                continue

            print('-------åˆ†é…å‡ºå»---------')
            print(f"{n}")
            print('-----å‰©é¤˜trialæ•¸---------')
            print(len(self.trials_scheduler))
            r = self.resource_run_time[resource_id]
            if math.isfinite(r) and r > 0:
                print('-----trialæ™‚é–“(ä¼°è¨ˆ)---------')
                print(math.ceil(r))
            print('----------------------------')

            # å•Ÿå‹•è¨“ç·´
            Trial.options(
                num_cpus=self.resource[resource_id]["CPU"],
                num_gpus=self.resource[resource_id]["GPU"],
                resources={self.resource[resource_id]["node"]: 0.1}
            ).remote(self.tuner, n, ids, hypers, checkpoints)

            self.start_trial_time[resource_id] = time.time()
            self.running_trial_num += n
            self.running_resource_num += 1
            self.resource[resource_id]["Used_count"] += cc
            for tid in ids:
                self.trials_state[tid]["resource_id"] = resource_id


    ##########################
    # TrialåŸ·è¡Œæ™‚é–“ç­–ç•¥æ’ç¨‹â²ï¸ #
    ##########################
    def ETA(self):
        # self.trials_scheduler = sorted(self.trials_scheduler, reverse=False)
        # self.trials_scheduler.sort(key = lambda t: self.trials_state[t]["iteration"])

        remaining_generations = 0
        for trial_state in self.trials_state:
            if trial_state["resource_id"] < 0:
                remaining_generations += math.ceil((self.max_iter - trial_state["iteration"]) / self.checkpoint_interval)
        cc = 1.0

        # --- ä¿®æ­£ç¨‹å¼ç¢¼é–‹å§‹ ---
        # 1. å‹•æ…‹è¨ˆç®—åŸºæº–æ™‚é–“
        # ç›´æ¥è¿­ä»£åˆ—è¡¨ self.resource_run_time
        valid_run_times = [t for t in self.resource_run_time if math.isfinite(t) and t > 0]

        if valid_run_times:
            # ä½¿ç”¨ç•¶å‰æœ€æ…¢ç¯€é»çš„æ™‚é–“ä½œç‚ºåŸºæº–
            adaptive_baseline_time = max(valid_run_times)
        else:
            # å¦‚æœé‚„æ²’æœ‰ä»»ä½•æœ‰æ•ˆçš„åŸ·è¡Œæ™‚é–“è¨˜éŒ„ï¼Œä½¿ç”¨ä¸€å€‹é è¨­å€¼
            adaptive_baseline_time = 150.0
        # --- ä¿®æ­£ç¨‹å¼ç¢¼çµæŸ ---

        if len(self.trials_scheduler):
            while True:
                if not len(self.avaliable_resource):
                    break

                resource_id = self.avaliable_resource.pop(0)
                n_ability = self.resource[resource_id]["calculate_ability"]
                ids = []
                hypers = []
                checkpoints = []
                n = 0 # Initialize n
                print('-----åŸæœ¬trialæ•¸---------')
                print(len(self.trials_scheduler))

                if n_ability >= 1 and self.resource[resource_id]["Used_count"] == 0.0:
                    n = 1
                    for i in range(n):
                        tid = self.trials_scheduler.pop(0)
                        ids.append(tid)
                        if (self.stop_iteration - self.trials_state[tid]["iteration"]) < self.checkpoint_interval:
                            self.checkpoints[tid]["checkpoint_interval"] = self.stop_iteration - self.trials_state[tid]["iteration"]
                        else:
                            self.checkpoints[tid]["checkpoint_interval"] = self.checkpoint_interval
                        hypers.append(self.hypers[tid])
                        checkpoints.append(self.checkpoints[tid])

                elif n_ability >= 1 and self.resource[resource_id]["Used_count"] != 0.0:
                    r = self.resource_run_time[resource_id]
                    if not math.isfinite(r) or r <= 0:
                        n = 1
                    else:
                        # ä½¿ç”¨è‡ªé©æ‡‰åŸºæº–æ™‚é–“ä¾†å–ä»£ 150.0
                        n = max(1, math.ceil(adaptive_baseline_time / r))
                    n = min(n, len(self.trials_scheduler))

                    print('ç§’æ•¸/ä¼°è¨ˆå–® trialï¼š')
                    print(r)
                    print('ç¸®çŸ­Tæ•¸')
                    print(n)

                    for i in range(n):
                        tid = self.trials_scheduler.pop(0)
                        ids.append(tid)
                        if (self.stop_iteration - self.trials_state[tid]["iteration"]) < self.checkpoint_interval:
                            self.checkpoints[tid]["checkpoint_interval"] = self.stop_iteration - self.trials_state[tid]["iteration"]
                        else:
                            self.checkpoints[tid]["checkpoint_interval"] = self.checkpoint_interval
                        hypers.append(self.hypers[tid])
                        checkpoints.append(self.checkpoints[tid])
                else: # n_ability is 0 or less
                        self.avaliable_resource.append(resource_id)
                        break

                if n == 0:
                    self.avaliable_resource.append(resource_id)
                    break

                print('-------åˆ†é…å‡ºå»---------')
                print(f"{n}")
                print('-----å‰©é¤˜trialæ•¸---------')
                print(len(self.trials_scheduler))
                r = self.resource_run_time[resource_id]
                if math.isfinite(r) and r > 0:
                    print('-----å–®å€‹trialæ™‚é–“(ä¼°è¨ˆ)---------')
                    print(math.ceil(r))
                print('----------------------------')

                Trial.options(
                    num_cpus=self.resource[resource_id]["CPU"],
                    num_gpus=self.resource[resource_id]["GPU"],
                    resources={self.resource[resource_id]["node"]: 0.1}
                ).remote(self.tuner, n, ids, hypers, checkpoints)

                self.start_trial_time[resource_id] = time.time()
                self.running_trial_num += n
                self.running_resource_num += 1
                self.resource[resource_id]["Used_count"] += cc
                for i in range(n):
                    self.trials_state[ids[i]]["resource_id"] = resource_id
                break



    # è™•ç†è¨“ç·´å®Œè¦çµæŸçš„trial
    def report_before_trial_end(self, n, ids, accuracys, run_times, checkpoints):
        end_trial_time = time.time()
        total_run_time = 0

        # æš«å­˜ resource_idï¼Œå› ç‚ºè¿´åœˆä¸­æœƒç”¨åˆ°
        # å‡è¨­åŒä¸€æ¬¡ Trial.remote çš„æ‰€æœ‰ trial éƒ½ä¾†è‡ªåŒä¸€å€‹ resource_id
        if not ids: # å¦‚æœ ids æ˜¯ç©ºçš„ï¼Œæå‰è¿”å›
            self.create_new_trial()
            return

        resource_id = self.trials_state[ids[0]]["resource_id"]

        for i in range(n):
            self.trial_acc_list[ids[i]] = accuracys[i]

            if checkpoints[i]["checkpoint_interval"] >= self.checkpoint_interval:
                mutation.remote(self.tuner, ids[i], self.hypers, self.trial_acc_list, self.last_checkpoint, self.hyperparam_mutations)

            # resource_id = self.trials_state[ids[i]]["resource_id"] # resource_id æ‡‰è©²æ˜¯å›ºå®šçš„
            self.trials_state[ids[i]]["resource_id"] = -1

            self.trials_state[ids[i]]["run_time"] += run_times[i]
            self.trials_state[ids[i]]["iteration"] += checkpoints[i]["checkpoint_interval"]
            self.checkpoints[ids[i]] = checkpoints[i]

            # æ–°å¢ï¼šè¨˜éŒ„æ¯æ¬¡å¯¦éš›ä½¿ç”¨åˆ°çš„ç¯€é»èˆ‡å°æ‡‰ batch size
            node = self.resource[resource_id]["node"]
            bs_used = int(self.hypers[ids[i]].get("batch_size", 0))
            self.node_batch_sizes_history.setdefault(node, set()).add(bs_used)

            total_run_time = run_times[i]
            if i == n - 1:
                # æ›´æ–°è©² resource çš„ã€Œå¹³å‡å–®å€‹ trial æ™‚é–“ã€ä¼°è¨ˆå€¼ï¼Œé¿å… ETA ä½¿ç”¨ inf æˆ– 0
                # run_times æ˜¯ç´¯ç©æ™‚é–“ï¼Œå› æ­¤ç”¨ run_times[-1] / n ç•¶ä½œå¹³å‡æ¯å€‹ trial çš„è€—æ™‚ä¼°è¨ˆ
                try:
                    avg_per_trial = max(1e-6, float(run_times[-1]) / max(1, n))
                except Exception:
                    avg_per_trial = float('inf')
                self.resource_run_time[resource_id] = avg_per_trial

                communication_time = end_trial_time - self.start_trial_time[resource_id] - total_run_time
                save_communication_time_to_txt.remote(self.log_dir, self.comm_log_filename, n, self.resource[resource_id],  self.trials_state[ids[i]]["iteration"], communication_time, total_run_time, run_times[i])
            save_acc_to_json.remote(ids[i], accuracys[i], self.trials_state[ids[i]]["iteration"], self.path)

            if self.resource[resource_id]["Used_count"] == 0.5:
                self.min_run_one_interval_time = min(self.min_run_one_interval_time, run_times[i])
                calculate_ability = math.ceil(run_times[i] / self.min_run_one_interval_time)
                for resource in self.resource:
                    if resource["calculate_ability"]:
                        self.resource[resource_id]["calculate_ability"] += int(calculate_ability / resource["calculate_ability"])
                self.resource[resource_id]["calculate_ability"] += calculate_ability
                print(self.resource[resource_id])

            if self.trials_state[ids[i]]["iteration"] > self.max_iter:
                self.max_iter = self.trials_state[ids[i]]["iteration"]
                self.last_run_interval = int((self.stop_iteration - self.max_iter) / self.checkpoint_interval * self.hyper_num)

            if accuracys[i] > self.max_acc:
                self.max_acc = accuracys[i]

            check = 0
            if self.stop_iteration:
                if self.trials_state[ids[i]]["iteration"] < self.stop_iteration:
                    check += 1
                else:
                    check = -9

            if self.stop_acc != 1:
                if accuracys[i] < self.stop_acc:
                    check += 1
                else:
                    check = -9
            if check > 0:
                if STALENESS:
                    self.insert_trial(ids[i])
                else:
                    self.trials_scheduler.append(ids[i])
            elif check < 0:
                self.trials_state[ids[i]]["resource_id"] = -2
            else:
                print("No end condition!!")
                exit(0)

        self.running_trial_num -= n
        self.running_resource_num -= 1

        # --- [ä¿®æ”¹æ­¤è™•] ---
        # æª¢æŸ¥æ˜¯å¦é€²å…¥ã€Œå¾ŒæœŸã€
        is_late_stage = self.max_iter >= self.LATE_STAGE_ITER_THRESHOLD
        # æª¢æŸ¥æ­¤ç¯€é»æ˜¯å¦ç‚ºã€Œå€™é¸å¼±ç¯€é»ã€
        is_candidate = (resource_id in self.weakest_node_ids)
        # æª¢æŸ¥æ˜¯å¦å·²é”æ·˜æ±°ä¸Šé™
        under_limit = len(self.weak_nodes_retired_set) < self.MAX_RETIRE_NODE_COUNT

        if is_late_stage and is_candidate and under_limit:
            # é€²å…¥å¾ŒæœŸï¼Œæ˜¯å€™é¸å¼±ç¯€é»ï¼Œä¸”å°šæœªé”ä¸Šé™ -> æ·˜æ±°å®ƒ
            print(f"--- é€²å…¥å¾ŒæœŸï¼šæ·˜æ±°å‰›å®Œæˆä»»å‹™çš„å¼±ç¯€é» {resource_id} (ç¸½æ·˜æ±°: {len(self.weak_nodes_retired_set)+1}/{self.MAX_RETIRE_NODE_COUNT}) ---")
            self.weak_nodes_retired_set.add(resource_id)
            # (é‡é»ï¼šä¸è¦åŸ·è¡Œ append)
        else:
            # éå¾ŒæœŸï¼Œæˆ–éå€™é¸ï¼Œæˆ–å·²é”ä¸Šé™ -> æ­£å¸¸åŠ å›å»
            # (æˆ‘å€‘ä¹Ÿæª¢æŸ¥å®ƒæ˜¯å¦"å·²ç¶“"åœ¨æ·˜æ±°åå–®ä¸­ï¼Œé¿å…æ„å¤–åŠ å›)
            if resource_id not in self.weak_nodes_retired_set:
                self.avaliable_resource.append(resource_id)
        # --- [ä¿®æ”¹çµæŸ] ---

        self.create_new_trial()

    # æ–°å¢ï¼šå–å¾—å„ç¯€é»æ­·å²ä½¿ç”¨éçš„ batch sizeï¼ˆå·²æ’åºçš„åˆ—è¡¨ï¼‰
    def get_node_batch_sizes_history(self):
        return {node: sorted(list(s)) for node, s in self.node_batch_sizes_history.items()}


    # æŸ¥çœ‹æ˜¯å¦å…¨éƒ¨éƒ½è¨“ç·´å®Œ
    def is_finish(self):
        if len(self.trials_scheduler) + self.running_trial_num == 0:
            return True
        else:
            return False

    # è¨­å®šheadçš„æŒ‡æ¨™
    def set_head(self, tuner):
        self.tuner = tuner

        for _ in range(len(self.resource)):
            self.create_new_trial()

    def set_after_mutation(self, id, chosed_id, new_hyper, last_checkpoint):
        self.last_checkpoint[id] = last_checkpoint

        if new_hyper:
            self.perturbs += 1
            self.hypers[id] = new_hyper
            self.checkpoints[id] = copy.deepcopy(self.checkpoints[chosed_id])

            # if self.trials_state[id]["iteration"] > self.trials_state[chosed_id]["iteration"]:
            #     if self.trials_state[id]["iteration"] == self.stop_iteration:
            #         self.trials_scheduler.append(id)
            #         self.trials_scheduler = sorted(self.trials_scheduler, reverse=False)
            #     self.trials_state[id]["iteration"] = self.trials_state[chosed_id]["iteration"]


    def get_for_reporter(self):
        return self.hypers, self.trial_acc_list, self.trials_state, self.perturbs, self.running_trial_num, self.package_size

    def get_start_time(self):
        return self.start_time

    def get_resource(self):
        return self.resource

    def get_best_accuracy(self):
        max_list = list(map(self.trial_acc_list.index, heapq.nlargest(1, self.trial_acc_list)))
        return max_list[0], self.trial_acc_list[max_list[0]], self.perturbs


# çªè®Š
@ray.remote(num_cpus = 0.1, resources={"node:"+HEAD_NODE_IP: 0.1})
def mutation(tuner, id, hypers, accuracys, last_checkpoint, hyperparam_mutations, resample_posibility = 0.25, quantile_fraction = 0.25):
    lower_quantile, upper_quantile = quantile(accuracys, quantile_fraction)
    if id in upper_quantile:
        last_checkpoint[id] = 1
    else:
        last_checkpoint[id] = 0

    new_hyper = None
    chosed_id = None

    if id in lower_quantile:      # æ˜¯å¦è¡¨ç¾å¾ˆå·®
        print("--- Exploit ---")
        chosed_id = random.choice(upper_quantile)       # é¸å‡ºä¸€å€‹å„ªç§€çš„Trial
        print(f"Cloning  hyper_{str(chosed_id).zfill(5)} (score : {accuracys[chosed_id]}) to hyper_{str(id).zfill(5)} (score : {accuracys[id]}) \n")
        if last_checkpoint[chosed_id] == 0:
            print(f"Hyper_{str(chosed_id).zfill(5)} don't have checkpoint, skip exploit for  hyper_{str(id).zfill(5)}!!")
        else:
            new_hyper = explore(id, hypers[chosed_id],  hyperparam_mutations, resample_posibility)      # çªè®Š

    tuner.set_after_mutation.remote(id, chosed_id, new_hyper, last_checkpoint[id])

# æ‰¾å‡ºæ¨™ç·šå„ªç§€è·Ÿå·®çš„
def quantile(accuracys, quantile_fraction):
    trials = []
    for id, acc in enumerate(accuracys):
        if acc != 0:
            trials.append(id)

    if len(trials) <= 1:
        return [], []

    trials.sort(key=lambda t: accuracys[t])

    # è¨ˆç®—num_trials_in_quantile
    num_trials_in_quantile = int(math.ceil(len(trials) * quantile_fraction))
    if num_trials_in_quantile > len(trials) / 2:
        num_trials_in_quantile = int(math.floor(len(trials) / 2))

    return (trials[:num_trials_in_quantile], trials[-num_trials_in_quantile:])

# æ¢ç´¢æ–°çš„hyper
def explore(id, hyper, hyperparam_mutations, resample_posibility):
    new_hyper = hyper
    print(f"--- Explore the hyperparameters on  hyper_{str(id).zfill(5)} ---")
    for key, distribution in hyperparam_mutations.items():
        print(f'{key} : {hyper[key]} --- ', end="")
        if isinstance(distribution, list):
            if random.random() < resample_posibility or hyper[key] not in distribution:
                val = random.choice(distribution)
                # è‹¥æ˜¯ batch_sizeï¼Œç¢ºä¿è½‰æˆ Python int
                new_hyper[key] = int(val) if key == "batch_size" else val
                print(f'(resample)   --> {new_hyper[key]}')
            else:
                shift = random.choice([-1, 1])
                old_idx = distribution.index(int(hyper[key]) if key == "batch_size" else hyper[key])
                new_idx = min(max(old_idx + shift, 0), len(distribution) - 1)
                val = distribution[new_idx]
                new_hyper[key] = int(val) if key == "batch_size" else val
                print(f"(shift {'left' if shift == -1 else 'right'}) --> {new_hyper[key]}")
        elif isinstance(distribution, tuple):
            if random.random() < resample_posibility:
                new_hyper[key] = random.uniform(distribution[0], distribution[1])
                print(f'(resample)   --> {new_hyper[key]}')
            else:
                mul = random.choice([0.8, 1.2])
                new_hyper[key] = hyper[key] * mul
                print(f'(* {mul})   --> {new_hyper[key]}')
    print()
    bs_list = BATCH_SIZE
    new_hyper["batch_size"] = bs_list[id % len(bs_list)]
    return new_hyper

@ray.remote(num_cpus = 0.1, resources={"node:"+HEAD_NODE_IP: 0.1})
def save_acc_to_json(id, acc, iter, path):
    jsonFile = open(path+'/'+str(id)+'-accuracy.json','a')
    data={
        "iteration":iter,
        "accuracy":acc,
    }
    w = json.dumps(data)    # ç”¢ç”Ÿè¦å¯«å…¥çš„è³‡æ–™
    jsonFile.write(w)       # å¯«å…¥è³‡æ–™
    jsonFile.write('\n')    # å¯«å…¥è³‡æ–™
    jsonFile.close()

@ray.remote(num_cpus=0.1, resources={"node:" + HEAD_NODE_IP: 0.1})
def save_communication_time_to_txt(log_dir, filename, trial_num, resources, iter, communication_time, total_run_time, run_times):
    os.makedirs(log_dir, exist_ok=True)
    out_path = os.path.join(log_dir, filename)
    with open(out_path, 'a') as communication_file:
        communication_file.write(f"resources : {resources}\n")
        communication_file.write(f"iter: {iter}\n")
        communication_file.write(f"num: {trial_num}\n")
        communication_file.write(f"trial_sec: {run_times}\n")
        communication_file.write(f"communication_time: {communication_time:.2f}\n")
        communication_file.write(f"total_run_time: {total_run_time:.2f}\n")
        communication_file.write(f"-----------------------------------------------\n")

# æœƒè¢«åˆ†é…ä¸€å€‹hyperï¼Œè¨­è¨ˆè¨“ç·´èˆ‡dataå‚³æ¥
@ray.remote
def Trial(tuner, n, ids, hypers, checkpoints):
    # Check for empty hypers to prevent crash
    if not hypers:
        return

    start_time = time.time()
    accs = []
    run_times = []

    model_type = hypers[0].get("model_type", "resnet-18")

    if model_type == "resnet-18":
        model = models.resnet18()
        model.fc = nn.Linear(model.fc.in_features, 10)
    elif model_type == "resnet-50":
        model = models.resnet50()
        model.fc = nn.Linear(model.fc.in_features, 100)

    # ä¾ batch_size å¿«å–ä¸åŒçš„ DataLoader
    loaders_cache = {}  # key: (model_type, batch_size) -> (train_loader, test_loader)

    for i in range(n):
        # å¼·åˆ¶è½‰ Python intï¼ˆé¿å… numpy.int64ï¼‰
        bs = int(hypers[i].get("batch_size", 512))
        key = (model_type, bs)
        if key not in loaders_cache:
            loaders_cache[key] = get_data_loader(model_type, bs)
        train_loader, test_loader = loaders_cache[key]

        if torch.cuda.is_available():
            device = torch.device("cuda")
            model = model.to(device)
            # Make sure checkpoint tensors are on the correct device
            for k, v in checkpoints[i]["model_state_dict"].items():
                checkpoints[i]["model_state_dict"][k] = v.to(device)
            for state in checkpoints[i]["optimizer_state_dict"]["state"].values():
                for k, v in state.items():
                    if isinstance(v, torch.Tensor):
                        state[k] = v.to(device)
        else:
            device = torch.device("cpu")

        model.load_state_dict(checkpoints[i]["model_state_dict"])
        optimizer = optim.SGD(model.parameters(), lr=hypers[i].get("lr", 0.01), momentum=hypers[i].get("momentum", 0.9))
        optimizer.load_state_dict(checkpoints[i]["optimizer_state_dict"])

        for param_group in optimizer.param_groups:
            if "lr" in hypers[i]:
                param_group["lr"] = hypers[i]["lr"]
            if "momentum" in hypers[i]:
                param_group["momentum"] = hypers[i]["momentum"]

        for _ in range(checkpoints[i]["checkpoint_interval"]):
            train(model, optimizer, train_loader, device)

        accs.append(test(model, test_loader, device))
        run_times.append(time.time() - start_time)

        # Move state dicts back to CPU before sending them back to the Tuner
        checkpoints[i]["model_state_dict"] = {k: v.cpu() for k, v in model.state_dict().items()}

        cpu_opt_state = copy.deepcopy(optimizer.state_dict())
        for state in cpu_opt_state['state'].values():
            for k, v in state.items():
                if isinstance(v, torch.Tensor):
                    state[k] = v.cpu()
        checkpoints[i]["optimizer_state_dict"] = cpu_opt_state


    tuner.report_before_trial_end.remote(n, ids, accs, run_times, checkpoints)

def allocate_trials_by_score(score_json_data, hyper_num):
    # 1. è’é›†æ‰€æœ‰ç¯€é»åˆ†æ•¸ï¼ˆ<=0 å¼·åˆ¶è¨­ç‚º1ï¼‰ï¼Œä½¿ç”¨å”¯ä¸€çš„éµä¾†å€åˆ†ä¸åŒè³‡æºçµ„
    score_dict = {}
    for node_type in ['CPU', 'GPU']:
        if node_type in score_json_data:
            for ip, info in score_json_data[node_type].items():
                # ä½¿ç”¨ IP å’Œè³‡æºé¡å‹ä½œç‚ºå”¯ä¸€çš„éµ
                key = f"{ip}_{node_type}"
                raw_score = info['score']
                score_dict[key] = max(1, raw_score)  # <=0 å¼·åˆ¶è¨­ç‚º1

    # å¦‚æœæ²’æœ‰ä»»ä½•ç¯€é»ï¼Œç›´æ¥è¿”å›
    if not score_dict:
        return {}

    # 2. ç¢ºä¿æ¯å€‹ç¯€é»è‡³å°‘åˆ†é…ä¸€å€‹ trial
    allocation = {key: 1 for key in score_dict}
    num_nodes = len(score_dict)

    # å¦‚æœ trials ç¸½æ•¸å°æ–¼ç¯€é»æ•¸ï¼Œå‰‡éƒ¨åˆ†ç¯€é»å¯èƒ½ç„¡æ³•åˆ†é…åˆ°
    if hyper_num < num_nodes:
        # åˆ†æ•¸é«˜çš„å„ªå…ˆåˆ†é…
        sorted_keys = sorted(score_dict.keys(), key=lambda k: score_dict[k], reverse=True)
        allocation = {key: 0 for key in score_dict}
        for i in range(hyper_num):
            allocation[sorted_keys[i]] = 1
        return allocation

    remaining_trials = hyper_num - num_nodes

    # 3. ä¾åˆ†æ•¸æ¯”ä¾‹åˆ†é…å‰©é¤˜çš„ trial
    # åªè¨ˆç®—æœ‰è³‡æ ¼ç²å¾—é¡å¤– trial çš„ç¯€é»çš„ç¸½åˆ†
    total_score_for_remaining = sum(score_dict.values())

    if total_score_for_remaining > 0:
        for key, score in score_dict.items():
            extra_trials = int(round(score / total_score_for_remaining * remaining_trials))
            allocation[key] += extra_trials

    # 4. ä¿®æ­£ allocationï¼Œç¢ºä¿ç¸½æ•¸ç­‰æ–¼ hyper_num
    allocated = sum(allocation.values())
    if allocated < hyper_num:
        # trialä¸å¤ ï¼Œä¾åºåˆ†çµ¦åˆ†æ•¸æœ€é«˜çš„
        sorted_keys = sorted(score_dict.keys(), key=lambda k: score_dict[k], reverse=True)
        remain = hyper_num - allocated
        idx = 0
        while remain > 0:
            allocation[sorted_keys[idx % len(sorted_keys)]] += 1
            remain -= 1
            idx += 1
    elif allocated > hyper_num:
        # trialå¤ªå¤šï¼Œå¾åˆ†æ•¸æœ€ä½çš„ç æ‰ï¼ˆä½†ä¸èƒ½ç åˆ°1ä»¥ä¸‹ï¼‰
        sorted_keys = sorted(score_dict.keys(), key=lambda k: score_dict[k])
        remain = allocated - hyper_num
        idx = 0
        while remain > 0:
            key = sorted_keys[idx % len(sorted_keys)]
            if allocation[key] > 1:
                allocation[key] -= 1
                remain -= 1
            idx += 1

    return allocation

if __name__=='__main__':
    parser = argparse.ArgumentParser(description = "Choose trial scheduling mode")
    parser.add_argument("--exp_times", type=int, default=1)
    parser.add_argument("--mode", type=str, default="ERA")
    args = parser.parse_args()
    if args.mode.upper() not in ["ETA", "ERA"]:
        raise KeyError(f"{args.mode} is not exists.")

    data_path = DATA_PATH
    dir_path= DIR_PATH

    # æ–°å¢ï¼šä¾æ¨¡å¼å»ºç«‹ç¨ç«‹çš„è¼¸å‡ºè³‡æ–™å¤¾
    MODE_NAME = args.mode.upper()
    LOG_DIR = os.path.join(dir_path, 'log_' + MODE_NAME)
    os.makedirs(LOG_DIR, exist_ok=True)

    # ç‚ºé€™æ¬¡å®Œæ•´çš„è…³æœ¬åŸ·è¡Œç”Ÿæˆä¸€å€‹å”¯ä¸€çš„é€šè¨Šæ—¥èªŒæ–‡ä»¶å
    current_time_str = time.strftime("%Y%m%d-%H%M%S")
    os.makedirs(os.path.join(LOG_DIR, 'communication_time'), exist_ok=True)
    comm_log_filename = f"communication_time/communication_results_{current_time_str}.txt"

    score_json_file = open(os.path.join(dir_path, 'score.json'),'r')
    score_json_data_original = json.load(score_json_file)
    score_json_file.close()

    trial_allocation = allocate_trials_by_score(score_json_data_original, HYPER_NUM)
    print("[Trial Allocation by Score]", trial_allocation)

    new_json = {"CPU": {}, "GPU": {}}
    for key, num_trials in trial_allocation.items():
        ip, node_type = key.split('_')
        # ç¢ºä¿ score_json_data_original ä¸­æœ‰å°æ‡‰çš„ core è³‡è¨Š
        if ip in score_json_data_original.get(node_type, {}):
            if ip not in new_json[node_type]:
                new_json[node_type][ip] = {"core": score_json_data_original[node_type][ip]["core"], "score": 0}
            new_json[node_type][ip]["score"] += num_trials

    # è¼¸å‡ºåˆ°æª”æ¡ˆ
    score_json_file_path = os.path.join(dir_path, 'temp_score.json')
    with open(score_json_file_path, 'w') as f:
        json.dump(new_json, f, indent=4)
    print(f"Trial allocation saved to {score_json_file_path}")

    # Tuner å°‡ä½¿ç”¨é€™å€‹æ–°çš„åˆ†é…æª”
    score_json_data = new_json

    runtime_env = {
        'working_dir': data_path,
        'excludes': ["data/", "my_model/", "ray_results/", "pytorch-cifar/"],
    }

    # æ”¹å¯«ï¼šRunning_Results.txt æ”¾åˆ° LOG_DIR ä¸‹é¢
    with open(os.path.join(LOG_DIR, "Running_Results.txt"), "a+") as out_result:
        out_result.write("+---------------+---------------+\n")
        out_result.write(f'{time.ctime()}  <<Our Results - {__file__}>> \n')
        out_result.write(f"Hyper_num = {HYPER_NUM} \n")
        out_result.write(f"Stop iteration = {STOP_ITER} \n")
        out_result.write(f"Stop accuracy = {STOP_ACC} \n")
        out_result.write(f"Checkpoint interval = {INTERVAL_CHECK} \n")
        out_result.write(f"Batch size = {BATCH_SIZE} \n")

        # --- [æ–°å¢] å¯«å…¥æ·˜æ±°ç¯€é»è¨­å®š ---
        out_result.write(f"Max Retire Nodes = {MAX_RETIRE_NODES} \n")
        # --- [æ–°å¢çµæŸ] ---

        out_result.write(f"Resource allocation: {RESOURCE_ALLOCATION} \n")

    model_types = ["resnet-18"]

    for model in model_types:
        with open(os.path.join(LOG_DIR, "Running_Results.txt"), "a+") as out_result:
            out_result.write(f"model_type: {model} \n")

        avg_run_time = 0
        avg_accuracy = 0

        for i in range(args.exp_times):
            if ray.is_initialized():
                ray.shutdown()
            ray.init(address="ray://"+HEAD_NODE_IP+":10001", runtime_env=runtime_env)
            print(ray.available_resources())

            tt = time.ctime()
            tt_tmp = tt.split()
            json_path = os.path.join(LOG_DIR, "results", f"{tt_tmp[-1]}-{tt_tmp[-4]}-{tt_tmp[-3]}-{tt_tmp[-2]}_run{i+1}/")
            os.makedirs(json_path, exist_ok=True)
            print(f'{json_path = }')

            # å»ºç«‹Tunerï¼Œä¸¦å‚³å…¥ log_dir å’Œå…±äº«çš„ comm_log_filename
            tuner_head = Tuner.remote(
                hyper_num = HYPER_NUM,
                model_type = model,
                resource_allocation = score_json_data,      # å¿…é ˆæ˜¯åŸå§‹æ ¼å¼ï¼ŒåŒ…å« "CPU"ã€"GPU"
                stop_acc = STOP_ACC,
                stop_iteration = STOP_ITER,
                checkpoint_interval = INTERVAL_CHECK,
                path = json_path,
                hyperparam_mutations = {
                    "lr": (0.0001, 1),
                    "momentum": (0.0001, 1),
                    "batch_size": (BATCH_SIZE)
                },
                trialmode = MODE_NAME,
                log_dir = LOG_DIR,
                comm_log_filename = comm_log_filename, # å‚³å…¥æœ¬æ¬¡åŸ·è¡Œå…±äº«çš„å”¯ä¸€æª”æ¡ˆå
                max_retire_nodes = MAX_RETIRE_NODES, # <-- [æ–°å¢] å‚³å…¥åƒæ•¸
            )

            tuner_head.set_head.remote(tuner_head)

            Reporter.remote(
                tuner_head,
                max_report_frequency = INTERVAL_REPORT,
                hyper_num = HYPER_NUM,
            )

            while(not ray.get(tuner_head.is_finish.remote())):
                time.sleep(1)

            max_acc_index, max_acc, perturbs = ray.get(tuner_head.get_best_accuracy.remote())
            start_time = ray.get(tuner_head.get_start_time.remote())
            avg_run_time += (time.time() - start_time)
            avg_accuracy += max_acc
            resource = ray.get(tuner_head.get_resource.remote())

            # å–å¾—å„ç¯€é»æ­·å²ä½¿ç”¨çš„ batch size ä¸¦å¯«å…¥ Running_Results.txt
            node_bs = ray.get(tuner_head.get_node_batch_sizes_history.remote())
            with open(os.path.join(LOG_DIR, "Running_Results.txt"), "a+") as out_result:
                out_result.write(f"\n--- Results for experiment run {i+1} ---\n")
                out_result.write("Batch size per node (historical usage):\n")
                for node, sizes in sorted(node_bs.items()):
                    out_result.write(f"  {node}: {sizes}\n")
                out_result.write(f"Resource results: {resource} \n")
            ray.shutdown()
            time.sleep(10)

        with open(os.path.join(LOG_DIR, "Running_Results.txt"), "a+") as out_result:
            out_result.write(f"\n--- Final Average Results ---\n")
            out_result.write(f"Avg_total_runtime : {avg_run_time/args.exp_times} \n")
            out_result.write(f"Avg_accuracy : {avg_accuracy/args.exp_times} \n\n")
